{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea49e9f2",
   "metadata": {},
   "source": [
    "## GPT-2 Text Generation with GPU Support\n",
    "This notebook demonstrates how to use the GPT-2 model from Hugging Face for text generation, with GPU acceleration if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7953b7",
   "metadata": {},
   "source": [
    "### Check GPU Availability\n",
    "First, we check if CUDA (GPU) is available on the system. If a GPU is available, we'll print its name. This helps us confirm whether we can use GPU acceleration for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079ec3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95473c1b",
   "metadata": {},
   "source": [
    "### Import Hugging Face Transformers\n",
    "Import the pipeline module from transformers library. This is a high-level API that makes it easy to use pre-trained models for various NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f854fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb4f0eb",
   "metadata": {},
   "source": [
    "### Initialize Model and Generate Text\n",
    "Here we:\n",
    "1. Specify the model (GPT-2) we want to use\n",
    "2. Set up the device (GPU if available, otherwise CPU)\n",
    "3. Create a text generation pipeline\n",
    "4. Define our prompt\n",
    "5. Generate text based on the prompt\n",
    "\n",
    "Parameters:\n",
    "- max_length: Maximum length of generated text (including prompt)\n",
    "- num_return_sequences: Number of different sequences to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45246704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "generator = pipeline('text-generation', model=model_name, device=device)  \n",
    "prompt = \"Once upon a time\"\n",
    "results = generator(prompt, max_length=30, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69669db0",
   "metadata": {},
   "source": [
    "### Display Generated Text\n",
    "Print the generated text. The output includes both our original prompt (\"Once upon a time\") and the AI-generated continuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761ae123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, when he was a child, I was in a little house on the outskirts of Berlin. I was just 19 years old and had been a part of a group of kids from my own village. I didn't know much about the history of the village, but when I was a kid I was all about exploring the forest, walking around the forest, exploring the woods. I had a small collection of books: I never read any of them, but I have read a lot of them. I was interested in history, so I started reading about the village. I started playing piano and singing. I heard a lot about the village, but I never did any reading, so I didn't know anything about it.\n",
      "\n",
      "In the beginning, the villagers were very different from the rest. They were very nice people, and they were very nice people. They always seemed to be doing things for the children's benefit. They were very kind people, and they were very good at what they did. They were very good at things they did, and they were very good at what they did.\n",
      "\n",
      "In the beginning, if you wanted to be a good child, you had to be a good person. Then you had to be a good person in order to be good\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(results[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
